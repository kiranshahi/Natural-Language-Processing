{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/kiranshahi/Natural-Language-Processing/blob/main/Natural_Language_Processing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2A2KFRhi2vWM"
      },
      "source": [
        "# Natural Langauage Processing\n",
        "\n",
        "## Sentiment Analysis\n",
        "\n",
        "### Problem description\n",
        "\n",
        "Though the Sentiment analysis problem is considered as the basic problem in natural language processing, it is still a challenging problem if we want to achieve a perfect performance. Because of the wide variety of writing styles, sarcasm, slang, etc.\n",
        "\n",
        "In this lab task, we are going to use the \"movie_reviews\" dataset from the nltk corpus. This dataset contains a set of 1000 positive and 1000 negative reviews.\n",
        "\n",
        "We can formulate this problem of sentiment analysis for movie reviews in the following ways.\n",
        "\n",
        "*   Load the positive and negative reviews separately into raw_data\n",
        "*   We generate the labels for the reviews, 0 for positive and 1 for negative. From \"raw_data\" and \"labels\", we split 80% data into the training set and 20% in the testing set.\n",
        "*   Convert the text into tf-idf / tf vectors.\n",
        "*   Train the data with naïve Bayes classifier. Since our data are discrete, we will use Multinomial Naïve Bayes classifier to train dataset.\n",
        "*   Next, we will evaluate the performance from the metrics of precision, recall and f1-score.\n",
        "\n",
        "### Implementation and Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mkl3ci7C21wJ",
        "outputId": "213b301f-6337-4dc1-f443-51b430b2d992"
      },
      "source": [
        "!pip install nltk\n",
        "import nltk\n",
        "from nltk.corpus import movie_reviews\n",
        "\n",
        "nltk.download('movie_reviews')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n",
            "[nltk_data] Downloading package movie_reviews to /root/nltk_data...\n",
            "[nltk_data]   Package movie_reviews is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BiNDOij024NB"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn import metrics\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyISw9e93BHY"
      },
      "source": [
        "# Get the positive and negative review IDs\n",
        "fileids_pos = movie_reviews.fileids('pos')\n",
        "fileids_neg = movie_reviews.fileids('neg')\n",
        "# Load the reviews\n",
        "raw_data = []\n",
        "for i in range(len(fileids_pos)):\n",
        "  raw_data.append(movie_reviews.raw(fileids_pos[i]))\n",
        "for i in range(len(fileids_neg)):\n",
        "  raw_data.append(movie_reviews.raw(fileids_neg[i]))\n",
        "\n",
        "# The corresponding labels for the reviews, 0 for postive, 1 for negative\n",
        "labels = [0] * len(fileids_pos) + [1] * len(fileids_neg)\n",
        "\n",
        "# Split the training and testing set by 80-20%\n",
        "X_train, X_test, Y_train, Y_test = train_test_split(raw_data, labels, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTRfVM_G3Dbx"
      },
      "source": [
        "# Calculate the tf-idf features from the training set\n",
        "def calculate_tf_tfid(is_tfidf):\n",
        "  tfidf = TfidfVectorizer(use_idf=is_tfidf)\n",
        "  tfidf_data = tfidf.fit_transform(X_train)\n",
        "  # print(tfidf_data.shape)\n",
        "  \n",
        "  # Train the naive Bayes model for prediction\n",
        "  classifier = MultinomialNB().fit(tfidf_data, Y_train)\n",
        "\n",
        "  test_performance(classifier, tfidf)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "esFH2OkUWWR4"
      },
      "source": [
        "# Evaluate the sentiment for each sentence in a review, and plot the variation of sentiment\n",
        "def plot_sentiment_variation(classifier, tfidf):\n",
        "  sentences = X_test[0].split('.')\n",
        "  testing_tfidf = tfidf.transform(sentences)\n",
        "  predictions = classifier.predict_proba(testing_tfidf)\n",
        "  polarity = [x[0] - x[1] for x in predictions]\n",
        "  # polarity = [x[0] if (x[0] > x[1]) else -x[1] for x in predictions]\n",
        "  \n",
        "  plt.xlabel('Sentences')\n",
        "  plt.ylabel('Polarity')\n",
        "  plt.plot(polarity)\n",
        "  plt.ylim(-1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwEjgJQ83ENv"
      },
      "source": [
        "# Performance on the testing set\n",
        "def test_performance(classifier, tfidf):\n",
        "  testing_tfidf = tfidf.transform(X_test)\n",
        "  predictions = classifier.predict(testing_tfidf)\n",
        "  print(metrics.classification_report(Y_test, predictions, target_names=['pos', 'neg']))\n",
        "  plot_sentiment_variation(classifier,tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "ANFC8PZhUdVd",
        "outputId": "70d819c3-27ef-4248-fbb5-f1f40b5bdb8d"
      },
      "source": [
        "#implementing the tf-idf feature\n",
        "print(\"Performance evaluation metrics for tf-idf feature\")\n",
        "calculate_tf_tfid(True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance evaluation metrics for tf-idf feature\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         pos       0.93      0.54      0.68       216\n",
            "         neg       0.64      0.95      0.76       184\n",
            "\n",
            "    accuracy                           0.73       400\n",
            "   macro avg       0.78      0.75      0.72       400\n",
            "weighted avg       0.80      0.73      0.72       400\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 467
        },
        "id": "45ut4nlQUfGa",
        "outputId": "1ba58854-5053-4aa6-cdea-e8d38ef01a19"
      },
      "source": [
        "#implementing the tf features\n",
        "print(\"Performance evaluation metrics for tf feature\")\n",
        "calculate_tf_tfid(False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Performance evaluation metrics for tf feature\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         pos       1.00      0.08      0.15       216\n",
            "         neg       0.48      1.00      0.65       184\n",
            "\n",
            "    accuracy                           0.50       400\n",
            "   macro avg       0.74      0.54      0.40       400\n",
            "weighted avg       0.76      0.50      0.38       400\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uPzxj2l_3Gi_"
      },
      "source": [
        "# print(X_train[0])\n",
        "# print(testing_tfidf[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WIThzwmh43kH"
      },
      "source": [
        "### Discussions\n",
        "In this task, we had implemented sentiment analysis using the simple word count (tf/tf-idf) features and naïve Bayes method on \"movie_reviews\" dataset, where we have 1000 positive and 1000 negative reviews.\n",
        "\n",
        "#### For tf feature\n",
        "When using the tf feature we got an accuracy of 0.79 which means our model is 79% accurate. The result shows that the precision for positive is 0.89 (89%) and negative is 0.73 (73%). It means that 89 out of 100 reviews that were predicted positive are correct and others are false predictions. Similarly, 73 out of 100 negative reviews predicted were correct and the rest are false predictions. In comparison, to the tf-idf feature, the accuracy of negative prediction is quite low.\n",
        "\n",
        "Likewise, the recall value for positive and negative prediction was 0.64 and 0.93 respectively. It means that model was able to predict 64 positive reviews out of 100 positive reviews. Similarly, it was able to predict 93 negative reviews out of 100 negative reviews which is pretty good.\n",
        "\n",
        "#### For tf-idf feature\n",
        "After using the tf-idf feature we got an accuracy of 0.83 which is higher than the tf feature. It means the sentiment analysis model using tf-idf feature is 83% accurate. From metrics for the performance evaluation displayed above, we got a precision of 0.84 for positive and 0.82 for negative. It means that 84% of the review predicted positive was correct and the rest were false prediction. Similarly, 82% of the review predicted negative was correct and the rest were false predictions.\n",
        "\n",
        "Likewise, the recall value for positive was 0.80 and negative was 0.85. It means that model was able to predict 80 positive reviews out of 100 positive reviews and 85 negative reviews out of 100 negative reviews."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dojzIpq14Cb3"
      },
      "source": [
        "## Text Classification\n",
        "\n",
        "### Problem description\n",
        "In this task, we are going to categories the document and assign it to one of 20 newsgroups. Here we have dataset called 20newsgroups from sklearn which contain the collection of message and 20 newsgroups such as 'sci.electronics', 'sci.crypt','comp.os.ms-windows.misc', 'rec.motorcycles' etc.\n",
        "\n",
        "We are going to use simple word count features like tf or tf-idf, and **Multinomial Naïve Bayes** as the method of classification.\n",
        "\n",
        "We can formulate a text classification problem in the following steps.\n",
        "\n",
        "\n",
        "*   20newsgroups dataset is divided into two subsets for training (development) and testing(performance evaluation). At first, we load the 'train' subset as training data.\n",
        "*   We convert train data into tf-idf or tf vectors.\n",
        "*   Next we train our data with Multinomial Naïve Bayes classifier.\n",
        "*   We load the testing set of data, convert it into tf-idf features and perform the classification.\n",
        "\n",
        "\n",
        "### Implementation and Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enAEFtsY4ZuQ"
      },
      "source": [
        "from sklearn.datasets import fetch_20newsgroups\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15tBb0dk4cbm"
      },
      "source": [
        "# Get the training dataset for the specified categoires\n",
        "categories = ['sci.electronics', 'sci.crypt',\n",
        "              'comp.os.ms-windows.misc', 'rec.motorcycles']\n",
        "training_data = fetch_20newsgroups(subset='train', categories=categories)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9r7A8r14iiH",
        "outputId": "49e0115a-add3-46aa-fe99-1e7cb973e491"
      },
      "source": [
        "# Create the tf-idf transformer\n",
        "tfidf = TfidfVectorizer(use_idf=True)\n",
        "# tfidf = TfidfVectorizer(use_idf=False)\n",
        "training_tfidf = tfidf.fit_transform(training_data.data)\n",
        "print(training_tfidf.shape)\n",
        "\n",
        "# Train a Multinomial Naive Bayes classifier\n",
        "classifier = MultinomialNB().fit(training_tfidf, training_data.target)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(2375, 64073)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "deOo4XPs4kRv"
      },
      "source": [
        "from sklearn import metrics\n",
        "\n",
        "testing_data = fetch_20newsgroups(subset='test', categories=categories)\n",
        "testing_tfidf = tfidf.transform(testing_data.data)\n",
        "predictions = classifier.predict(testing_tfidf)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i2UalAU4mIg",
        "outputId": "9e407de1-0f1f-4960-d8d0-ef1054f6fd29"
      },
      "source": [
        "errors = [i for i in range(len(predictions)) if predictions[i] != testing_data.target[i]]\n",
        "\n",
        "for i, post_id in enumerate(errors[:5]):\n",
        "  print(\"------------------------------------------------------------------\")\n",
        "  print(\"%s --> %s\\n\" %(testing_data.target_names[testing_data.target[post_id]], \n",
        "                      testing_data.target_names[predictions[post_id]]))\n",
        "  print(testing_data.data[post_id])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------------------------------------------\n",
            "sci.electronics --> rec.motorcycles\n",
            "\n",
            "From: jeffj@cbnewsm.cb.att.com (jeffrey.n.jones)\n",
            "Subject: SPICE for XT with no co-processer?\n",
            "Organization: AT&T\n",
            "Distribution: usa\n",
            "Lines: 10\n",
            "\n",
            "I want to run SPICE on my XT so I can learn more about amplifiers\n",
            "and oscilators. Is there a version of this that will run on my XT\n",
            "with no math co-processer, if so where can I get it? Thanks for any\n",
            "and all help!\n",
            "\n",
            "Jeff\n",
            "-- \n",
            " Jeff Jones  AB6MB         |  OPPOSE THE NORTH AMERICAN FREE TRADE AGREEMENT!\n",
            " jeffj@seeker.mystic.com   |  Canada/USA Free Trade cost Canada 400,000 jobs. \n",
            " Infolinc BBS 415-778-5929 |  Want to guess how many we'll lose to Mexico?\n",
            "\n",
            "------------------------------------------------------------------\n",
            "sci.electronics --> sci.crypt\n",
            "\n",
            "From: me170pjd@emba-news.uvm.edu.UUCP (Peter J Demko)\n",
            "Subject: Re: PC parallel I (!= I/O)\n",
            "Originator: me170pjd@freehold.emba.uvm.edu\n",
            "Organization: University of Vermont -- Division of EMBA Computer Facility\n",
            "Lines: 19\n",
            "\n",
            "From article <1993Apr26.110250.5243@nmt.edu>, by erickson@azure.nmt.edu (Alan Erickson):\n",
            "> \tI'm trying to bring in 8+ bits to a PC, and would like\n",
            "> \tto use interrupt-driven routines. Without buying an IO\n",
            "> \tboard or making a new port, _where_ can I bring in these\n",
            "> \tbits? LPT seems to have only a few inputs, but I've heard\n",
            "> \trumours that some LPTs have bidirectional lines. Anybody\n",
            "> \tknow fer sure? If any bi-d LPTs, which boards have them\n",
            "> \t(I'll be running a new 386DX-33)?\n",
            "> \n",
            "> ------------------------------------------------------------------\n",
            "> Alan Erickson   erickson@baltic.nmt.edu\t\t\n",
            "> \n",
            "> to all SunRayce '93 competitors: I hope you're getting\n",
            "> about as much sleep as I am.....\n",
            "> ------------------------------------------------------------------\n",
            "\n",
            "I'M WATCHING ONE BEING BUILT RIGHT HERE AT UVM AND THE TEAM IS \n",
            "SHAGGIN' IT THESE DAYS.\n",
            "                                 ME170PJD@UVM.EDU\n",
            "\n",
            "------------------------------------------------------------------\n",
            "sci.electronics --> sci.crypt\n",
            "\n",
            "From: squish@endor.uucp (Shishin Yamada)\n",
            "Subject: Re: Laser vs Bubblejet?\n",
            "Organization: Aiken Computation Lab, Harvard University\n",
            "Lines: 56\n",
            "\n",
            "\tJust thought I would add $0.02 to DeskJet thread. I got my\n",
            "first one in college about 5 or so years ago.\n",
            "\n",
            "\tI've been a happy HP user of the DeskWriter for Macintosh for\n",
            "past 5 years. I got one just a few months after their release. And I\n",
            "got software revision 1.0a (now I'm up to rev. 3.1. Our family (sister\n",
            "and father) have each purchased their own DW's after seeing mine go\n",
            "for one year unscathed (their stuck to their trusty ImageWriter II's).\n",
            "The original DW has gone for 5 years at moderate personal use. I would\n",
            "say that it has gone through at least 15,000 sheets, and around one\n",
            "(small) ink cartridge every 3 months or so.\n",
            "\n",
            "\tMy brother might take this DW now (I'm probably gonna give it\n",
            "to him), and I am looking to upgrade to a color DW. The chief\n",
            "advantages/disadvantages I've found over the years are:\n",
            "\n",
            "Advantages:\tQuick (2-3 ppm), Quiet (roomate can sleep while it's\n",
            "printing), AppleTalk Networkable (unfortunately the original wasn't,\n",
            "so look out if you buy used. I rewired our home with phonenet\n",
            "AppleTalk connectors, and while home, we can all use my dad's one\n",
            "DW!), and cheap (now run ~$300). BTW, you can upgrade older DW's to\n",
            "color or for appletalk, I dunno if HP still does the upgrades, but I\n",
            "received many offers (I just didn't ned it however). Also, crisp\n",
            "laser-quality output is a wonder (used to really impress those\n",
            "ImageWriter Dot-Matrix people so much so, that I had to charge $0.25\n",
            "per sheet to stop my college dorm neighbors from bothering me at all\n",
            "hours of the night....)\n",
            "\n",
            "Disadvantages.\tInk used to be hard to find, and wasn't cheap, and\n",
            "wasn't originally water-proof. While HP has done wonders with the ink\n",
            "(I dunno if it's still toxic), it is still subjet to smearing and\n",
            "running (if you run around in the damp Boston rain, and get your\n",
            "bookbag completely soaked). Ink now runs about $14-$15 for small carts\n",
            "(I get mine from Elek-Tek in Chicago, I think they're now down to\n",
            "$12). The ink carts used to say they're dated for only 6 months, but\n",
            "I don't think they say so anymore. We stick to a 4 month supply (of\n",
            "about 3 carts). We use cheap Hammerhill Laser Print paper (after\n",
            "fooling for a long time. Laser/Xerox paper is also good). Smearing\n",
            "doesn't happen, unless you have a brand new ink cart and you grab the\n",
            "paper and smudge it all over as soon as it comes out of the machine.\n",
            "Other disadvantages are : No Postscript (this can be an advantage in\n",
            "speed, usually). Ways around this are Ghostscript or Freedom of Press\n",
            "software solutions. I bet HP probably has a PS prototype inkjet, but\n",
            "they won't release it for fear of hurting LJ sales.\n",
            "\n",
            "In the end, the primary advantages of laser are true postscript\n",
            "(unless you go for cheap lasers), and fused toner (no smearing, even\n",
            "when soaking in water). Lasers are slightly sharper, but the only\n",
            "instance where I needed precise layouts was Printed Circuit Board\n",
            "Transparencies for PhotoEtching. I found a Textronix color Phaser\n",
            "Postscript (Thermal Wax Transfer) to work the best to make PCB\n",
            "negatives directly onto a transparency.\n",
            "\n",
            "Well, hope my babbling has helped.\n",
            "-squish@endor.harvard.edu\n",
            "\n",
            "\n",
            "------------------------------------------------------------------\n",
            "sci.electronics --> sci.crypt\n",
            "\n",
            "From: ggruscho@nyx.cs.du.edu (George Gruschow)\n",
            "Subject: Re: How to the disks copy protected.\n",
            "Organization: University of Denver, Dept. of Math & Comp. Sci.\n",
            "Lines: 29\n",
            "\n",
            "ketil@edb.tih.no (Ketil Albertsen,TIH) writes:\n",
            "\n",
            ">In article <1993Apr20.230749.12821@reed.edu>, mblock@reed.edu (Matt Block) writes:\n",
            "\n",
            ">>\tI guess what I am saying is that your question is difficult, if not\n",
            ">>impossible, to answer.  What exactly do you want to know?  Do you need a good\n",
            ">>one for a project you are working on?  How secure must it be?  Are you trying\n",
            ">>to crack one that someone else has used?  I can probably make suggestions,\n",
            ">>assuming the activity is strictly legal.  (In general, it is a BAD idea,\n",
            ">>legally, to tamper with copy protection.  It can also lead to corruption of\n",
            ">>files which you necessarily do not have back ups of (being as they are copy\n",
            ">>protected,) which can be devestating.)  Do you have absolutely no ideas for\n",
            ">>practical applications, and are merely curious?\n",
            ">>\tPlease clear up those questions, and I'll try to help as much as I\n",
            ">>can.\n",
            "\n",
            ">May we interpret this as an offer to volunteer as editor for a\n",
            ">\"Copy protection FAQ\" ? I am quite sure that I am not alone welcoming such\n",
            ">an initiative! *I* will volunteer to ask some of the questions, if you will\n",
            ">provide the answers :-)\n",
            "\n",
            ">Ketil Albertsen\n",
            "\n",
            "That's great.  Read my article.  Edit out the personal formality, and save.\n",
            "--\n",
            "-------------------------------------------------------------------------------\n",
            "George Gruschow                                Death do you gronk.\n",
            "ag625@yfn.ysu.edu                              ggruscho@nyx.cs.du.edu\n",
            "-------------------------------------------------------------------------------\n",
            "\n",
            "------------------------------------------------------------------\n",
            "sci.electronics --> sci.crypt\n",
            "\n",
            "From: CONRADIE@firga.sun.ac.za (Gerrit Conradie)\n",
            "Subject: Re: How to make the disks copy protected (continued)\n",
            "Organization: University of Stellenbosch, SA\n",
            "Lines: 31\n",
            "\n",
            "In article <sehari.735962071@du139-201.cc.iastate.edu> sehari@iastate.edu (Babak Sehari) writes:\n",
            ">From: sehari@iastate.edu (Babak Sehari)\n",
            ">Subject: How to make the disks copy protected (continued)\n",
            ">Date: Wed, 28 Apr 1993 01:54:31 GMT\n",
            ">---\n",
            ">\n",
            ">The discussion under the old topic went in the wrong direction.  Some people,\n",
            ">instead of discussing the issue itself, they decided to discuss the\n",
            ">non-technical part of the issue.  So, Here I go with my limited knowledge\n",
            ">about this issue.  Hoping you guys cut the crap and talk about the real\n",
            ">technical ways to do this.  The methods that I am aware that are effective\n",
            ">are:\n",
            ">\n",
            ">1- Laser hole burning.  This would leave the disk damaged, so if you format\n",
            ">   that particular sector of the disk you can not write to it.  It is very \n",
            "                                           ^^^^^^^^^^^^^^^^^^^\n",
            "Laser holes are (or were) used to prevent someone from making exact copies \n",
            "of a disk. You do not want to write to the damaged disk, only read and use \n",
            "the programs.\n",
            "\n",
            ">   hard for crackers to damage the disk exactly the same way.\n",
            ">\n",
            "\n",
            "I remember a program called Copywrite that could copy a disk with a laser \n",
            "hole in it. I think it simulates the laser hole. After copying the disk the \n",
            "program is, if necessary, used in conjunction with a program called Nokey or \n",
            "something. (The program tells you which program to use)\n",
            "\n",
            "No solution.\n",
            "\n",
            "- gerrit\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "w56BWmrfmXkB",
        "outputId": "5436627e-915c-44d5-ec8e-dd452f2f861a"
      },
      "source": [
        "print(metrics.classification_report(testing_data.target, predictions, target_names=categories))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                         precision    recall  f1-score   support\n",
            "\n",
            "        sci.electronics       0.98      0.83      0.90       394\n",
            "              sci.crypt       0.95      0.97      0.96       398\n",
            "comp.os.ms-windows.misc       0.69      0.98      0.81       396\n",
            "        rec.motorcycles       0.98      0.69      0.81       393\n",
            "\n",
            "               accuracy                           0.87      1581\n",
            "              macro avg       0.90      0.87      0.87      1581\n",
            "           weighted avg       0.90      0.87      0.87      1581\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmnASnFB471X"
      },
      "source": [
        "### Discussions\n",
        "In this task, we had classified the messages into 4 different groups. For this, we took 20newsgroups datasets from sklearn and implemented simple word count features like tf and tf-idf for representation of text and Multinomial Naïve Bayes for classification.\n",
        "\n",
        "From the above metrics for performance evaluation, we can conclude that the accuracy of the model was 87% approx which is pretty good. For classification we had classified the message into four class 'sci.electronic', 'sci.crypt', 'comp.os.ms-windows.misc' and 'rec.motorcycles'.\n",
        "\n",
        "For sci.electronics the precision value was 0.98, the recall was 0.83 and the f1-score of 0.90. It means that 98% of the message that was predicted under the group of sci.electronics were true and the remaining 2% predicted for sci.electronics category falls under a different category. Similarly, 83% of messages from group sci.electronics were predicted as sci.electronics and remaining messages from sci.electronics group were predicted something else.\n",
        "\n",
        "95% of the message that was predicted under the group of sci.crypt were true and the remaining 5% were false predictions. Similarly, 97% of messages from group sci.crypt were predicted as sci.crypt and the remaining messages from sci.crypt group were predicted something else.\n",
        "\n",
        "69% of the message that was predicted under the group of comp.os.ms-windows.misc were true and the remaining were false predictions which is quite low. Similarly, 98% of messages from group comp.os.ms-windows.misc were predicted as comp.os.ms-windows.misc and remaining messages from comp.os.ms-windows.misc group were predicted something else.\n",
        "\n",
        "98% of the message that was predicted under the group of rec.motorcycles were true and the remaining were false predictions. Similarly, 69% of messages from group rec.motorcycles were predicted as rec.motorcycles and the remaining message from rec.motorcycles group were predicted something else.\n",
        "\n",
        "From the observation of the f1-score, we find that sci.crypt group higher value i.e. 0.96. So, we can conclude that the classification performs pretty well for sci.crypt group."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0XOM-yvk5ESP"
      },
      "source": [
        "## Topic Modelling\n",
        "\n",
        "### Problem description\n",
        "\n",
        "Topic modelling is a type of statistical modelling where we aim to discover the hidden semantic structures from a large set of text known as the corpus (collections of documents).\n",
        "\n",
        "Here we are going to use the Laten Dirichlet Allocation (LDA) as a topic model to classify the text in a document. It assumes that each document in a corpus has one or more hidden topics, and each topic is supported by the number of words.\n",
        "\n",
        "We are going to find these hidden topics and their supporting words by maximising the posterior probability of the whole corpus with the given topics and words. `p(corpus|topics,words)`\n",
        "\n",
        "### Implementation and Results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iAGhrm7k5MGQ"
      },
      "source": [
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.snowball import SnowballStemmer\n",
        "from gensim import models, corpora\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "orUekeYW5Qp3"
      },
      "source": [
        "documents = [\n",
        "  \"\"\"\n",
        "  Machine learning (ML) is the study of computer algorithms that can improve automatically through experience and by the use of data. \n",
        "  It is seen as a part of artificial intelligence. Machine learning algorithms build a model based on sample data, known as training data, \n",
        "  in order to make predictions or decisions without being explicitly programmed to do so. \n",
        "  Machine learning are used in a wide variety of applications, such as in medicine, email filtering, speech recognition, \n",
        "  and computer vision, where it is difficult or unfeasible to develop conventional algorithms to perform the needed tasks.\n",
        "  We’re in the age where machines are no different. Machine Learning is still fairly a new concept. \n",
        "  We can teach machines how to learn and some machines can even learn on its own. This is magical phenomenon is called Machine Learning.\n",
        "  \".\n",
        "  \"\"\",\n",
        "  \"\"\"\n",
        "  Indian market on a working day, opens at 9:00 AM and closes at 3:30 PM. \n",
        "  The price of the stocks when the market opens is called the opening price. \n",
        "  The price of the stocks when the market closes is called the closing price. \n",
        "  Through the session, the stocks also hit two more values of importance \n",
        "  which are the day’s highest price and the day’s lowest price.\n",
        "  A market is where trading of stocks happen. Traders are of two kinds.\n",
        "  Trader who buys stocks and a trader who sells stocks. Sellers offer the stocks and buyers bid the stocks. \n",
        "  If there is buying pressure and buyers bid at a higher price and the stock prices rise, we call this state of market as bullish.\n",
        "  \"\"\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gVgssI3p5TvP",
        "outputId": "dcaa868f-4db2-4295-d2ca-b1a9ea242a17"
      },
      "source": [
        "# Clean the data by using stemming and stopwords removal\n",
        "\n",
        "nltk.download('stopwords')\n",
        "def stemming(documents):\n",
        "  stemmer = SnowballStemmer('english')\n",
        "  stop_words = stopwords.words('english')\n",
        "  texts = [\n",
        "           [stemmer.stem(word) for word in document.lower().split() if word not in stop_words]\n",
        "           for document in documents\n",
        "          ]\n",
        "  return texts\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wiaXsPFM5VkW"
      },
      "source": [
        "texts = stemming(documents)\n",
        "\n",
        "# Create a dictionary from the words\n",
        "dictionary = corpora.Dictionary(texts)\n",
        "\n",
        "# Create a document-term matrix\n",
        "doc_term_mat = [dictionary.doc2bow(text) for text in texts]\n",
        "\n",
        "# Generate the LDA model \n",
        "num_topics = 2\n",
        "ldamodel = models.ldamodel.LdaModel(doc_term_mat, \n",
        "        num_topics=num_topics, id2word=dictionary, passes=25)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s3Z4x2XJ5Xkv",
        "outputId": "fc7dbcd9-0099-4350-a3d6-ea5761137572"
      },
      "source": [
        "num_words = 5\n",
        "for item in ldamodel.print_topics(num_topics=num_topics, num_words=num_words):\n",
        "  print(f'\\nTop {num_words} contributing words for {(\"first\" if item[0] == 0 else \"second\" )} document:')\n",
        "  list_of_strings = item[1].split(' + ')\n",
        "  for text in list_of_strings:\n",
        "    details = text.split('*')\n",
        "    print(\"%-12s:%0.2f%%\" %(details[1], 100*float(details[0])))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Top 5 contributing words for first document:\n",
            "\"machin\"    :1.00%\n",
            "\"stock\"     :1.00%\n",
            "\"call\"      :1.00%\n",
            "\"price\"     :1.00%\n",
            "\"learn\"     :1.00%\n",
            "\n",
            "Top 5 contributing words for second document:\n",
            "\"machin\"    :4.40%\n",
            "\"stock\"     :3.80%\n",
            "\"learn\"     :3.30%\n",
            "\"market\"    :2.80%\n",
            "\"price\"     :2.80%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WHLLbW9p5Z7O",
        "outputId": "fb62e651-4a98-45fd-dbc4-d588c500ec03"
      },
      "source": [
        "new_docs = [\n",
        "  \"\"\"\n",
        "  Stock market prediction and analysis are some of the most difficult jobs to complete. There are numerous causes for this,\n",
        "  including market volatility and a variety of other dependent and independent variables that influence the value of a certain stock \n",
        "  in the market. These variables make it extremely difficult for any stock market expert to anticipate the rise and fall of the \n",
        "  market with great precision. However, with the introduction of Machine Learning and its strong algorithms, the most recent market research \n",
        "  and Stock Market Prediction advancements have begun to include such approaches in analyzing stock market data. In summary, Machine Learning \n",
        "  Algorithms are widely utilized by many organizations in Stock market prediction. This article will walk through a simple implementation \n",
        "  of analyzing and forecasting the stock prices of a Popular Worldwide Online Retail Store in Python using various Machine Learning Algorithms.\n",
        "  \"\"\"\n",
        "]\n",
        "\n",
        "new_texts = stemming(new_docs)\n",
        "new_doc_term_mat = [dictionary.doc2bow(text) for text in new_texts]\n",
        "\n",
        "vector = ldamodel[new_doc_term_mat]\n",
        "print(vector[0])\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0, 0.01581701), (1, 0.984183)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hh0ScO_c5bwX"
      },
      "source": [
        "### Discussions\n",
        "In this task, we had built an LDA model for and discovered the abstract topics that occurred in the collection of documents.\n",
        "\n",
        "#### First document\n",
        "For the first document, the top five contributing words are machin (6.70%), learn (5.10%), algorithm (2.80%), data, (2.00%) and use (2.00%)respectively. The document was about machine learning and the topic suggested by the model is related to it which is expected.\n",
        "\n",
        "#### Second document\n",
        "For the second document, the top five contributing words are stock (6.40%), price (4.70%), market (4.70%), call (3.00%) and price. (3.00%)respectively. The document was about the stock market and the topic suggested by the model is related to it, which is as expected.\n",
        "\n",
        "#### New document\n",
        "For this, we picked the article related to implementation in the Machine learning stock market. So, that it contains the topic related to both documents. After computing its projection vector from the LDA model we got the following result. \n",
        "\n",
        "`[(0, 0.45192024), (1, 0.5480798)]`\n",
        "\n",
        "The result shows that the new document has content related to both the first and second documents."
      ]
    }
  ]
}